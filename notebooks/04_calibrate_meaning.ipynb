{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating Meaning Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests and improves how we measure whether a changed sentence still means the same as the original.  \n",
    "It uses example pairs with human ratings to find the best way to automatically score meaning similarity, aiming to match human opinions as closely as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../promptsmith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptsmith.dspy_init import get_dspy\n",
    "dspy = get_dspy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the golden set and printing few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 dev examples and 12 test examples\n"
     ]
    }
   ],
   "source": [
    "from promptsmith.golden.load import load_golden_set\n",
    "\n",
    "\n",
    "dev_set, test_set = load_golden_set(judge_name=\"meaning\", seed=42)\n",
    "\n",
    "print(f\"Loaded {len(dev_set)} dev examples and {len(test_set)} test examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Input: Linda borrowed the book from Mark yesterday.\n",
      "Output: Mark borrowed the book from Linda yesterday.\n",
      "Gold score: 0.6\n",
      "Gold reasoning: Roles reversed; rest identical.\n",
      "\n",
      "Example 2:\n",
      "Input: The novel was written by George Orwell in 1949.\n",
      "Output: The novel was written by J. K. Rowling in 1949.\n",
      "Gold score: 0.2\n",
      "Gold reasoning: Author misattributed; timeframe correct but misleading.\n",
      "\n",
      "Example 3:\n",
      "Input: He earned a salary of $75,000 last year.\n",
      "Output: He earned a salary of $750,000 last year.\n",
      "Gold score: 0.2\n",
      "Gold reasoning: Order‑of‑magnitude hallucination.\n"
     ]
    }
   ],
   "source": [
    "def print_examples(examples, n=1):\n",
    "    for i in range(min(n, len(examples))):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Input: {examples[i].input_text}\")\n",
    "        print(f\"Output: {examples[i].output_text}\")\n",
    "        print(f\"Gold score: {examples[i].gold_score}\")\n",
    "        print(f\"Gold reasoning: {examples[i].gold_reasoning}\")\n",
    "\n",
    "print_examples(dev_set, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline prompt is the original set of instructions given to the model for judging whether the meaning of a sentence is preserved after it’s rewritten.  \n",
    "It asks the model to compare the original and rewritten sentences, check if all important ideas are still present, and give a score from 0 (meaning lost) to 1 (meaning fully kept), along with an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in evaluating meaning preservation.\n",
      "\n",
      "Your task is to determine whether the restructured text preserves the essential meaning of the original input text.\n",
      "\n",
      "Please consider:\n",
      "1. Are all key ideas and important details still present?\n",
      "2. Were any important parts of the original meaning lost or changed significantly?\n",
      "3. Are minor rephrasings or small generalizations acceptable if they don't distort the overall meaning?\n",
      "\n",
      "Assign a score between 0 (poor preservation) and 1 (perfect preservation).\n",
      "\n",
      "Explain your reasoning clearly, mentioning what was preserved well and any important losses or changes.\n"
     ]
    }
   ],
   "source": [
    "from promptsmith.judges import JudgeMeaning\n",
    "from dspy import Predict\n",
    "\n",
    "baseline_judge = Predict(JudgeMeaning)\n",
    "print(baseline_judge.signature.instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calibrating the judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:49:13 INFO dspy.evaluate.evaluate: Average Metric: 38.0 / 48 (79.2%)\n",
      "2025/05/04 13:49:13 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/05/04 13:49:13 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/05/04 13:49:13 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=3 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline dev acc: 79.170\n",
      "Bootstrapping set 1/3\n",
      "Bootstrapping set 2/3\n",
      "Bootstrapping set 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]2025/05/04 13:49:15 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'Linda borrowed the book from Mark yesterday.', 'output_text': 'Mark borrowed the book from Linda yesterday.', 'gold_score': 0.6, 'gold_reasoning': 'Roles reversed; rest identical.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 10%|█         | 1/10 [00:02<00:22,  2.50s/it]2025/05/04 13:49:18 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'The novel was written by George\\xa0Orwell in 1949.', 'output_text': 'The novel was written by J.\\u202fK.\\xa0Rowling in 1949.', 'gold_score': 0.2, 'gold_reasoning': 'Author misattributed; timeframe correct but misleading.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 20%|██        | 2/10 [00:05<00:20,  2.51s/it]2025/05/04 13:49:20 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'He earned a salary of $75,000 last year.', 'output_text': 'He earned a salary of $750,000 last year.', 'gold_score': 0.2, 'gold_reasoning': 'Order‑of‑magnitude hallucination.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 30%|███       | 3/10 [00:07<00:16,  2.33s/it]2025/05/04 13:49:23 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'The vaccine trial enrolled 5,000 participants across five countries.', 'output_text': 'The vaccine trial enrolled 4,000 participants across five countries.', 'gold_score': 0.6, 'gold_reasoning': 'Participant number altered; rest accurate.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 40%|████      | 4/10 [00:10<00:15,  2.56s/it]2025/05/04 13:49:26 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'The spacecraft entered Mars orbit after a seven‑month journey.', 'output_text': 'The spacecraft landed on Mars after a seven‑month journey.', 'gold_score': 0.4, 'gold_reasoning': 'Orbit ↔ landing; related but major distinction.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 50%|█████     | 5/10 [00:13<00:13,  2.72s/it]2025/05/04 13:49:28 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'Regular exercise improves cardiovascular health.', 'output_text': 'Regular exercise is the leading cause of heart disease.', 'gold_score': 0.2, 'gold_reasoning': 'Direct contradiction of central statement.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 60%|██████    | 6/10 [00:14<00:09,  2.43s/it]2025/05/04 13:49:29 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'The museum opens at 10\\u202fa.m.', 'output_text': 'The museum opens at 10\\u202fp.m.', 'gold_score': 0.4, 'gold_reasoning': 'Confuses a.m. with p.m.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 70%|███████   | 7/10 [00:16<00:06,  2.25s/it]2025/05/04 13:49:31 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'When Rachel finished the project, she emailed it to her manager.', 'output_text': 'After completing the project, Rachel sent it to her supervisor via email.', 'gold_score': 1.0, 'gold_reasoning': 'All entities and actions preserved.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 80%|████████  | 8/10 [00:18<00:04,  2.19s/it]2025/05/04 13:49:34 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'input_text': 'He ran a marathon in 3\\xa0hours and 45\\xa0minutes last Sunday.', 'output_text': 'He ran a marathon last Sunday.', 'gold_score': 0.8, 'gold_reasoning': 'Time detail dropped; core event intact.'}) (input_keys={'input_text', 'output_text'}) with <function score_agreement_metric at 0x105a86700> due to getattr(): attribute name must be string.\n",
      " 90%|█████████ | 9/10 [00:23<00:02,  2.60s/it]\n",
      "2025/05/04 13:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: Error generating few-shot examples: getattr(): attribute name must be string\n",
      "2025/05/04 13:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: Running without few-shot examples.\n",
      "2025/05/04 13:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/05/04 13:49:36 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2025/05/04 13:49:43 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing instructions...\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are an expert in evaluating meaning preservation.\n",
      "\n",
      "Your task is to determine whether the restructured text preserves the essential meaning of the original input text.\n",
      "\n",
      "Please consider:\n",
      "1. Are all key ideas and important details still present?\n",
      "2. Were any important parts of the original meaning lost or changed significantly?\n",
      "3. Are minor rephrasings or small generalizations acceptable if they don't distort the overall meaning?\n",
      "\n",
      "Assign a score between 0 (poor preservation) and 1 (perfect preservation).\n",
      "\n",
      "Explain your reasoning clearly, mentioning what was preserved well and any important losses or changes.\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a language model evaluator specialized in meaning preservation. Your task is to assess whether the restructured text maintains the essential meaning of the original input text. \n",
      "\n",
      "Consider the following criteria in your evaluation:\n",
      "1. Are all key ideas and important details still present in the restructured text?\n",
      "2. Did any significant parts of the original meaning get lost or altered?\n",
      "3. Are minor rephrasings or small generalizations permissible if they do not distort the overall meaning?\n",
      "\n",
      "After your assessment, assign a score between 0 (poor preservation) and 1 (perfect preservation). Provide a clear explanation of your reasoning, highlighting what aspects of the meaning were preserved effectively and noting any critical losses or changes.\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a specialist in assessing semantic fidelity in text transformations. Your objective is to evaluate whether a paraphrased version of a given text maintains the core meaning of the original content. \n",
      "\n",
      "Please analyze the following:\n",
      "1. Are all significant concepts and critical details retained in the paraphrase?\n",
      "2. Have any essential elements of the original meaning been altered or omitted?\n",
      "3. Is it acceptable for there to be minor rephrasings or generalizations, provided they do not misrepresent the overall meaning?\n",
      "\n",
      "Rate the preservation of meaning on a scale from 0 (poor preservation) to 1 (perfect preservation). \n",
      "\n",
      "In your explanation, clearly outline what aspects of the meaning were well-preserved and identify any notable losses or changes that occurred during the paraphrasing process.\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/05/04 13:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 7 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.30 / 38 (82.4%): 100%|██████████| 38/38 [00:12<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:50:23 INFO dspy.evaluate.evaluate: Average Metric: 31.300000000000004 / 38 (82.4%)\n",
      "2025/05/04 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 82.37\n",
      "\n",
      "2025/05/04 13:50:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 7 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.10 / 35 (80.3%): 100%|██████████| 35/35 [00:13<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:50:37 INFO dspy.evaluate.evaluate: Average Metric: 28.10000000000001 / 35 (80.3%)\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1'].\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.29]\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37]\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.37\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
      "\n",
      "\n",
      "2025/05/04 13:50:37 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 7 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.30 / 35 (83.7%): 100%|██████████| 35/35 [00:14<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:50:51 INFO dspy.evaluate.evaluate: Average Metric: 29.299999999999997 / 35 (83.7%)\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 83.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0'].\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.29, 83.71]\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37]\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.37\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
      "\n",
      "\n",
      "2025/05/04 13:50:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 7 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.40 / 35 (81.1%): 100%|██████████| 35/35 [00:11<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:51:03 INFO dspy.evaluate.evaluate: Average Metric: 28.399999999999995 / 35 (81.1%)\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 81.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1'].\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.29, 83.71, 81.14]\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37]\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.37\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
      "\n",
      "\n",
      "2025/05/04 13:51:03 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 7 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.05 / 35 (80.1%): 100%|██████████| 35/35 [00:11<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:51:14 INFO dspy.evaluate.evaluate: Average Metric: 28.050000000000008 / 35 (80.1%)\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2'].\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.29, 83.71, 81.14, 80.14]\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37]\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.37\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
      "\n",
      "\n",
      "2025/05/04 13:51:14 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 7 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.40 / 35 (81.1%): 100%|██████████| 35/35 [00:10<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:51:25 INFO dspy.evaluate.evaluate: Average Metric: 28.400000000000006 / 35 (81.1%)\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 81.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0'].\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.29, 83.71, 81.14, 80.14, 81.14]\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37]\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.37\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: ========================================\n",
      "\n",
      "\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 7 - Full Evaluation =====\n",
      "2025/05/04 13:51:25 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 82.425) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.45 / 38 (82.8%): 100%|██████████| 38/38 [00:11<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:51:36 INFO dspy.evaluate.evaluate: Average Metric: 31.45 / 38 (82.8%)\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 82.76\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [82.37, 82.76]\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 82.76\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/05/04 13:51:36 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 82.76!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 13:51:56 INFO dspy.evaluate.evaluate: Average Metric: 37.6 / 48 (78.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned dev acc: 78.330\n"
     ]
    }
   ],
   "source": [
    "from promptsmith.judges.metrics import calibrate_judge\n",
    "\n",
    "calibrated_judge, found_optimized = calibrate_judge(devset=dev_set, judge_class=JudgeMeaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No better prompt found - using baseline\n",
      "\n",
      "=== BASELINE PROMPT ===\n",
      "You are an expert in evaluating meaning preservation.\n",
      "\n",
      "Your task is to determine whether the restructured text preserves the essential meaning of the original input text.\n",
      "\n",
      "Please consider:\n",
      "1. Are all key ideas and important details still present?\n",
      "2. Were any important parts of the original meaning lost or changed significantly?\n",
      "3. Are minor rephrasings or small generalizations acceptable if they don't distort the overall meaning?\n",
      "\n",
      "Assign a score between 0 (poor preservation) and 1 (perfect preservation).\n",
      "\n",
      "Explain your reasoning clearly, mentioning what was preserved well and any important losses or changes.\n"
     ]
    }
   ],
   "source": [
    "if found_optimized:\n",
    "    print(\"\\nOptimization successful - found better prompt!\")\n",
    "    print(\"\\n=== BASELINE PROMPT ===\")\n",
    "    print(baseline_judge.signature.instructions)\n",
    "    print(\"\\n=== OPTIMIZED PROMPT ===\")\n",
    "    print(calibrated_judge.signature.instructions)\n",
    "else:\n",
    "    print(\"\\nNo better prompt found - using baseline\")\n",
    "    print(\"\\n=== BASELINE PROMPT ===\")\n",
    "    print(baseline_judge.signature.instructions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
