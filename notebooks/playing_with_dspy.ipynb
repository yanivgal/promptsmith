{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../promptsmith')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptsmith.dspy_init import get_dspy\n",
    "dspy, lm = get_dspy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of floors in the castle David Gregory inherited is not specified in the information provided.\n"
     ]
    }
   ],
   "source": [
    "# Define a module (ChainOfThought) and assign it a signature (return an answer, given a question).\n",
    "qa = dspy.ChainOfThought('question -> answer')\n",
    "\n",
    "response = qa(question=\"How many floors are in the castle David Gregory inherited?\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the last call to the LLM, with all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm.history)  # e.g., 3 calls to the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'messages', 'kwargs', 'response', 'outputs', 'usage', 'cost', 'timestamp', 'uuid', 'model', 'response_model', 'model_type'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'cost': 8.235e-05,\n",
      "  'kwargs': {},\n",
      "  'messages': [ { 'content': 'Your input fields are:\\n'\n",
      "                             '1. `question` (str)\\n'\n",
      "                             'Your output fields are:\\n'\n",
      "                             '1. `reasoning` (str)\\n'\n",
      "                             '2. `answer` (str)\\n'\n",
      "                             'All interactions will be structured in the '\n",
      "                             'following way, with the appropriate values '\n",
      "                             'filled in.\\n'\n",
      "                             '\\n'\n",
      "                             '[[ ## question ## ]]\\n'\n",
      "                             '{question}\\n'\n",
      "                             '\\n'\n",
      "                             '[[ ## reasoning ## ]]\\n'\n",
      "                             '{reasoning}\\n'\n",
      "                             '\\n'\n",
      "                             '[[ ## answer ## ]]\\n'\n",
      "                             '{answer}\\n'\n",
      "                             '\\n'\n",
      "                             '[[ ## completed ## ]]\\n'\n",
      "                             'In adhering to this structure, your objective '\n",
      "                             'is: \\n'\n",
      "                             '        Given the fields `question`, produce the '\n",
      "                             'fields `answer`.',\n",
      "                  'role': 'system'},\n",
      "                { 'content': '[[ ## question ## ]]\\n'\n",
      "                             'How many floors are in the castle David Gregory '\n",
      "                             'inherited?\\n'\n",
      "                             '\\n'\n",
      "                             'Respond with the corresponding output fields, '\n",
      "                             'starting with the field `[[ ## reasoning ## ]]`, '\n",
      "                             'then `[[ ## answer ## ]]`, and then ending with '\n",
      "                             'the marker for `[[ ## completed ## ]]`.',\n",
      "                  'role': 'user'}],\n",
      "  'model': 'openai/gpt-4o-mini',\n",
      "  'model_type': 'chat',\n",
      "  'outputs': [ '[[ ## reasoning ## ]]\\n'\n",
      "               'The question asks for the number of floors in the castle that '\n",
      "               'David Gregory inherited. However, without specific context or '\n",
      "               'details about the castle in question, it is impossible to '\n",
      "               'provide an accurate answer. The number of floors in a castle '\n",
      "               'can vary widely depending on its design, size, and historical '\n",
      "               'context. \\n'\n",
      "               '\\n'\n",
      "               '[[ ## answer ## ]]\\n'\n",
      "               'The number of floors in the castle David Gregory inherited is '\n",
      "               'not specified in the information provided.\\n'\n",
      "               '\\n'\n",
      "               '[[ ## completed ## ]]'],\n",
      "  'prompt': None,\n",
      "  'response': ModelResponse(id='chatcmpl-BTkglaijgkufurn0k9xzU8hLAzfSy', created=1746430683, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_dbaca60df0', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## reasoning ## ]]\\nThe question asks for the number of floors in the castle that David Gregory inherited. However, without specific context or details about the castle in question, it is impossible to provide an accurate answer. The number of floors in a castle can vary widely depending on its design, size, and historical context. \\n\\n[[ ## answer ## ]]\\nThe number of floors in the castle David Gregory inherited is not specified in the information provided.\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=94, prompt_tokens=173, total_tokens=267, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default', cache_hit=None),\n",
      "  'response_model': 'gpt-4o-mini-2024-07-18',\n",
      "  'timestamp': '2025-05-05T10:38:04.699715',\n",
      "  'usage': { 'completion_tokens': 94,\n",
      "             'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None),\n",
      "             'prompt_tokens': 173,\n",
      "             'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None),\n",
      "             'total_tokens': 267},\n",
      "  'uuid': '53c08ebb-6799-42db-ace0-0b256b0d552b'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(lm.history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Multiple Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's something great about the ColBERT retrieval model?\"\n",
    "\n",
    "answer_a_question = dspy.ChainOfThought('question -> answer', n=5)\n",
    "\n",
    "response = answer_a_question(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A great aspect of the ColBERT retrieval model is its ability to effectively combine dense and sparse retrieval techniques, achieving high accuracy and efficiency through a late interaction mechanism.',\n",
       " 'One great aspect of the ColBERT retrieval model is its use of late interaction, which enables efficient and scalable retrieval while maintaining high accuracy by combining the strengths of both dense and sparse retrieval methods.',\n",
       " \"One great aspect of the ColBERT retrieval model is its efficient late interaction mechanism, which allows it to utilize BERT's powerful contextual embeddings while maintaining high retrieval speed, making it suitable for large-scale applications.\",\n",
       " 'One great thing about the ColBERT retrieval model is its efficient late interaction mechanism, which allows it to combine the powerful contextual embeddings of BERT with scalable retrieval, making it effective for large datasets while maintaining high accuracy.',\n",
       " 'One great aspect of the ColBERT retrieval model is its efficient late interaction mechanism, which allows it to combine the benefits of dense embeddings with traditional retrieval speed, making it highly effective for large-scale document retrieval.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.completions.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: One of the great aspects of the ColBERT retrieval model is its ability to combine the advantages of both dense and sparse retrieval methods. ColBERT utilizes a two-step approach where it first creates dense representations of queries and documents, allowing for efficient similarity calculations, and then employs a late interaction mechanism to selectively compare these representations. This enables it to achieve high retrieval accuracy while maintaining efficiency, making it suitable for large-scale information retrieval tasks. Additionally, its architecture allows for flexible integration with existing dense retrieval systems, enhancing performance without extensive modifications.\n",
      "Answer: A great aspect of the ColBERT retrieval model is its ability to effectively combine dense and sparse retrieval techniques, achieving high accuracy and efficiency through a late interaction mechanism.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reasoning: {response.reasoning}\")\n",
    "print(f\"Answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check LLM Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai/gpt-4o-mini': {'completion_tokens': 800,\n",
       "  'prompt_tokens': 173,\n",
       "  'total_tokens': 973,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0,\n",
       "   'text_tokens': None},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0,\n",
       "   'cached_tokens': 0,\n",
       "   'text_tokens': None,\n",
       "   'image_tokens': None}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_lm_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a mix of relief and disappointment\n",
      "The person likely feels relief from finally being outside after being in a dark room for a long time, as it can be refreshing to experience natural light and fresh air. However, the disappointment comes from the fact that it is raining outside, which may dampen their mood and prevent them from fully enjoying the experience of being outdoors.\n"
     ]
    }
   ],
   "source": [
    "feeling_analyzer = dspy.Predict('sentence, situation -> the_actual_feeling_of_the_person_in_the_sentence: str, reasoning: str')\n",
    "\n",
    "sentence=\"i went outside after a long time being in a dark room\"\n",
    "situation=\"it's raining outside\"\n",
    "response = feeling_analyzer(sentence=sentence, situation=situation)\n",
    "\n",
    "print(response.the_actual_feeling_of_the_person_in_the_sentence)\n",
    "print(response.reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: The output text captures the general idea of going shopping and buying some items, but it omits several key details from the original text. Specifically, it does not mention that the shopping was for dinner ingredients, nor does it include the fact that cheese was forgotten, which is a significant detail that affects the overall meaning of the narrative. While the main actions (going shopping and buying certain items) are preserved, the context and completeness of the story are lost. Therefore, the changes are not acceptable as they alter the essential meaning of the original text.\n",
      "Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from promptsmith.judges.judge_meaning import JudgeMeaning\n",
    "\n",
    "judge_meaning = dspy.Predict(JudgeMeaning)\n",
    "\n",
    "input_text = (\n",
    "    \"Yesterday, I went to the grocery store to buy ingredients for dinner. \"\n",
    "    \"I ended up buying fruits, vegetables, and pasta. When I got home, I realized I forgot the cheese.\"\n",
    ")\n",
    "\n",
    "output_text = (\n",
    "    \"I went shopping yesterday to get food. I bought some fruits, vegetables, and pasta.\"\n",
    ")\n",
    "\n",
    "result = judge_meaning(input_text=input_text, output_text=output_text)\n",
    "\n",
    "print(\"Reasoning:\", result.reasoning)\n",
    "print(\"Score:\", result.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the task of restructuring text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Original Text:\n",
      "----------------------\n",
      "I was trying to fix the kitchen sink. At first, I thought it was a clog, but it turned out to be a broken pipe. Water was everywhere, and I had no tools. I called my friend who had some plumbing experience, and he came over. Together we shut off the water and replaced the pipe, which took us the entire afternoon.\n",
      "----------------------\n",
      "\n",
      "📘 Restructured Text:\n",
      "----------------------\n",
      "### Fixing the Kitchen Sink: A Plumbing Adventure\n",
      "\n",
      "Recently, I faced a challenge while trying to fix my kitchen sink. Initially, I suspected that a clog was the issue, but I soon discovered that the real problem was a broken pipe.\n",
      "\n",
      "As water spilled everywhere, I realized I didn't have the necessary tools to handle the situation. In a moment of urgency, I called my friend, who has some plumbing experience. He quickly came over to help me.\n",
      "\n",
      "Together, we worked to shut off the water supply and replace the broken pipe. This task took us the entire afternoon, but we managed to resolve the issue successfully.\n",
      "----------------------\n",
      "\n",
      "🧠 Reasoning:\n",
      "The original text describes a personal experience of fixing a kitchen sink, detailing the initial assumption of a clog, the discovery of a broken pipe, and the subsequent actions taken with a friend's help. The restructured version will include a clear title, a brief introduction summarizing the situation, and organized paragraphs that simplify the language while maintaining the original meaning.\n",
      "\n",
      "🤖 DSPy History:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-05-05T10:38:16.495796]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `input_text` (str): The original long text.\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `output_text` (str): The restructured text with a title, intro, and clean paragraphs.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## input_text ## ]]\n",
      "{input_text}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## output_text ## ]]\n",
      "{output_text}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a text restructuring expert.\n",
      "        \n",
      "        Your job is to take long, dense text and rewrite it to make it easier to read and understand.\n",
      "        \n",
      "        Instructions:\n",
      "        1. Add a clear and informative title that reflects the topic.\n",
      "        2. Write a short intro paragraph summarizing the overall idea.\n",
      "        3. Break the rest of the text into logically organized paragraphs (one idea per paragraph).\n",
      "        4. Simplify the language where possible, but do not change the meaning.\n",
      "        5. Keep the tone natural and human.\n",
      "        \n",
      "        Do not invent new information. Stay faithful to the original content.\n",
      "        \n",
      "        Return only the restructured version, including the title at the top.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## input_text ## ]]\n",
      "I was trying to fix the kitchen sink. At first, I thought it was a clog, but it turned out to be a broken pipe. Water was everywhere, and I had no tools. I called my friend who had some plumbing experience, and he came over. Together we shut off the water and replaced the pipe, which took us the entire afternoon.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## output_text ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The original text describes a personal experience of fixing a kitchen sink, detailing the initial assumption of a clog, the discovery of a broken pipe, and the subsequent actions taken with a friend's help. The restructured version will include a clear title, a brief introduction summarizing the situation, and organized paragraphs that simplify the language while maintaining the original meaning.\n",
      "\n",
      "[[ ## output_text ## ]]\n",
      "### Fixing the Kitchen Sink: A Plumbing Adventure\n",
      "\n",
      "Recently, I faced a challenge while trying to fix my kitchen sink. Initially, I suspected that a clog was the issue, but I soon discovered that the real problem was a broken pipe.\n",
      "\n",
      "As water spilled everywhere, I realized I didn't have the necessary tools to handle the situation. In a moment of urgency, I called my friend, who has some plumbing experience. He quickly came over to help me.\n",
      "\n",
      "Together, we worked to shut off the water supply and replace the broken pipe. This task took us the entire afternoon, but we managed to resolve the issue successfully.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from promptsmith.tasks.restructure_text import RestructureText\n",
    "\n",
    "text_to_restructure = (\n",
    "    \"I was trying to fix the kitchen sink. At first, I thought it was a clog, but it turned out to be a broken pipe. \"\n",
    "    \"Water was everywhere, and I had no tools. I called my friend who had some plumbing experience, and he came over. \"\n",
    "    \"Together we shut off the water and replaced the pipe, which took us the entire afternoon.\"\n",
    ")\n",
    "\n",
    "restructure = dspy.ChainOfThought(RestructureText)\n",
    "restructured_text = restructure(input_text=text_to_restructure)\n",
    "\n",
    "\n",
    "print(\"\\n📝 Original Text:\")\n",
    "print(\"----------------------\")\n",
    "print(text_to_restructure)\n",
    "print(\"----------------------\")\n",
    "\n",
    "print(\"\\n📘 Restructured Text:\")\n",
    "print(\"----------------------\")\n",
    "print(restructured_text.output_text)\n",
    "print(\"----------------------\")\n",
    "\n",
    "print(\"\\n🧠 Reasoning:\")\n",
    "print(restructured_text.reasoning)\n",
    "\n",
    "print(\"\\n🤖 DSPy History:\")\n",
    "print(dspy.inspect_history(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluating the restructured text using ensemble judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptsmith.judges.ensemble_judge import EnsembleJudge\n",
    "import os\n",
    "\n",
    "judge_path = os.path.abspath(\"../promptsmith/judges/judge_restructure_text.yaml\")\n",
    "\n",
    "judge = EnsembleJudge(judge_path)\n",
    "verdict = judge(input_text=text_to_restructure, output_text=restructured_text.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_verdict(verdict):\n",
    "\n",
    "    print(\"\\n📊 Evaluation Results:\")\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    store = verdict._store\n",
    "\n",
    "    # Find all score, reasoning, and weight fields\n",
    "    score_fields = [k for k in store if k.endswith('_score') and k != 'combined_score']\n",
    "    reasoning_fields = [k for k in store if k.endswith('_reasoning')]\n",
    "    weight_fields = {k.replace('_weight', ''): store[k] for k in store if k.endswith('_weight')}\n",
    "\n",
    "    # Display overall score\n",
    "    overall = store.get('combined_score')\n",
    "    if overall is None and score_fields:\n",
    "        # Fallback: average of all scores\n",
    "        overall = sum(store[k] for k in score_fields) / len(score_fields)\n",
    "    print(f\"\\n🌟 Overall Score: {overall:.3f}\\n\")\n",
    "\n",
    "    # For each judge, display name, score, weight, and reasoning\n",
    "    # Sort for consistent order\n",
    "    for field in sorted(score_fields):\n",
    "        judge_key = field.replace('_score', '')\n",
    "        judge_name = judge_key.replace('_', ' ').title()\n",
    "        reasoning_field = field.replace('_score', '_reasoning')\n",
    "        score = store[field]\n",
    "        reasoning = store.get(reasoning_field, \"\")\n",
    "        weight = weight_fields.get(judge_key, None)\n",
    "        if weight is not None:\n",
    "            print(f\"### {judge_name} Analysis (score={score:.2f}, weight={weight})\")\n",
    "        else:\n",
    "            print(f\"### {judge_name} Analysis (score={score:.2f})\")\n",
    "        print(reasoning)\n",
    "        print()  # Blank line between judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Results:\n",
      "----------------------\n",
      "\n",
      "🌟 Overall Score: 0.990\n",
      "\n",
      "### Focus Relevance Analysis (score=1.00, weight=0.25)\n",
      "The restructured text maintains a strong focus on the original message about fixing the kitchen sink. It closely follows the sequence of events, detailing the initial diagnosis of a clog, the discovery of a broken pipe, the lack of tools, and the assistance from a friend. Each sentence adds relevant information without drifting off-topic or introducing unrelated content. The narrative style enhances engagement while remaining true to the original experience. Overall, the rewrite effectively captures the essence of the original text without unnecessary filler or generalizations.\n",
      "\n",
      "### Meaning Analysis (score=1.00, weight=0.25)\n",
      "The restructured text maintains the essential meaning of the original input. Key ideas such as the initial assumption of a clog, the discovery of a broken pipe, the urgency of the situation due to water spilling everywhere, and the involvement of a friend with plumbing experience are all preserved. The narrative flow is slightly enhanced with a more structured format and additional descriptive language, but these changes do not distort the overall meaning. The details about the time taken to resolve the issue and the collaborative effort are also retained. Overall, the changes are acceptable and enhance readability without losing any critical information.\n",
      "\n",
      "### Readability Analysis (score=0.90, weight=0.1)\n",
      "The text is easy to read due to its clear structure and straightforward language. The sentences are simple and concise, making it easy for the reader to follow the narrative. The paragraphs are organized logically, progressing from the initial problem to the resolution. The use of accessible vocabulary avoids confusion, and the flow from one idea to the next is smooth, enhancing overall readability.\n",
      "\n",
      "### Structure Analysis (score=1.00, weight=0.4)\n",
      "The text is well-structured and organized. It begins with a clear and relevant title that sets the context for the narrative. The introductory paragraph effectively summarizes the situation, providing a hook for the reader. The main ideas are presented in coherent paragraphs, detailing the progression of the plumbing issue and the resolution. The sequence of information flows logically, moving from the initial problem to the actions taken to resolve it. Overall, the structure supports the narrative well, making it easy to follow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_verdict(verdict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
